{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image classification of Dog and Cat using Transfer Learning\n",
    "\n",
    "when we have a relative small Dataset, a Transfer Learning is a super-effective technique. It's consist of using a pre-trained model.\n",
    "This model has been Trained on an extremely large dataset, and we would be able to transfer weights which were learned through\n",
    "hundreds of hours of training on multiple high powered GPUs. \n",
    "\n",
    "We are using in this project the **Inception-v3** model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's import the necessary Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "from keras_preprocessing.image import ImageDataGenerator, load_img, img_to_array, array_to_img\n",
    "from keras.layers import Dense, Flatten, Dropout\n",
    "from keras.models import Model\n",
    "from keras.optimizers import RMSprop, Adam, Adagrad\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember you must download the dataset. You can found it in Kaggle(Dogs Cats image classification Dataset). \n",
    "I done it and save in my local computer space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define the Dataset path and Train_set and Test_set directory\n",
    "\n",
    "db_path = \"C:/Users/nguim/OneDrive/Bureau/Learning/Project ML/Datasets/dogs_cats_dataset\"\n",
    "\n",
    "train_dir = os.path.join(db_path, 'train')\n",
    "test_dir = os.path.join(db_path, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(train_dir))\n",
    "print(type(test_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Preprocessing and Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input, \n",
    "    rescale=1./255, \n",
    "    shear_range=0.2,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    rotation_range=35, \n",
    "    zoom_range=0.3,\n",
    "    horizontal_flip=True, \n",
    "    data_format='channels_last'\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input, \n",
    "    rescale=1./255,\n",
    "    shear_range=0.2, \n",
    "    width_shift_range=0.2, \n",
    "    height_shift_range=0.2, \n",
    "    rotation_range=35, \n",
    "    zoom_range=0.3, \n",
    "    horizontal_flip=True, \n",
    "    data_format='channels_last'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_generate = train_datagen.flow_from_directory(\n",
    "    train_dir, \n",
    "    target_size=(299, 299), \n",
    "    batch_size=32, \n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "\n",
    "test_set_generate = test_datagen.flow_from_directory(\n",
    "    test_dir, \n",
    "    target_size=(299, 299), \n",
    "    batch_size=32, \n",
    "    class_mode='binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(train_set_generate))\n",
    "print(type(test_set_generate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's plot the first nine images and labels in the train_set_generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the first batch of images and labels\n",
    "images, labels = next(train_set_generate)\n",
    "\n",
    "# Plot the first nine images and their labels\n",
    "fig, axs = plt.subplots(3, 3, figsize=(4, 4))\n",
    "for i in range(9):\n",
    "    ax = axs[i//3, i%3]\n",
    "    ax.imshow(images[i] / 255)\n",
    "    ax.set_title(f\"Label: {labels[i]}\")\n",
    "    ax.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the first nine image with theirs label looks all black(not on their original color). This ay due to the fact that we used the\n",
    "\"preprocessing_function\" in the ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's define the base model or the pre_trained_modelof Transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_shape = (299, 299, 3)\n",
    "\n",
    "pre_trained_model = InceptionV3(\n",
    "    input_shape=image_shape, \n",
    "    include_top=False,  # leave out the last fully connected layer\n",
    "    weights='imagenet'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's make all the layer of pre_trained_model non trainable. \n",
    "# That means we freeze the models parameters\n",
    "\n",
    "pre_trained_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see the summary of base model\n",
    "\n",
    "pre_trained_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's build our principal Model \n",
    "\n",
    "Our model is going to use the pre_trained_model as a root. \n",
    "We use binary_crossentropy as the loss metric as we have 2 target classes. \n",
    "Our Optimizer is RMSprop with learning rate of 0.001(you can experiment wit Adam or Adagrad optimizer\n",
    "this will also work well)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the output layer of pre_trained_model to 1 dimension\n",
    "x = Flatten()(pre_trained_model.output)\n",
    "\n",
    "# Let's add a fully connected layer with 102 hidden init and ReLU activation function \n",
    "x = Dense(1024, activation='relu')(x)\n",
    "\n",
    "# Let's add the Dropout of rate 0.2\n",
    "x = Dropout(0.2)(x)\n",
    "\n",
    "# Now let's add our final layer for classification\n",
    "x = Dense(1, activation='sigmoid')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's define now our model base on pre_trained_model\n",
    "model = Model(pre_trained_model.input, x)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before we train our model, let compile it\n",
    "model.compile(\n",
    "    optimizer= RMSprop(learning_rate=0.001), \n",
    "    loss='binary_crossentropy', \n",
    "    metrics= ['acc']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's train our model\n",
    "callbacks = myCallback()\n",
    "model.fit_generator(\n",
    "    train_set_generate, \n",
    "    validation_data= test_set_generate, \n",
    "    epochs=5, \n",
    "    steps_per_epoch=5, \n",
    "    validation_steps=3, \n",
    "    verbose=2, \n",
    "    callbacks=[callbacks]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
